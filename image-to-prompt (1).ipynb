{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:18:12.796767Z","iopub.execute_input":"2023-06-22T16:18:12.797280Z","iopub.status.idle":"2023-06-22T16:18:30.756901Z","shell.execute_reply.started":"2023-06-22T16:18:12.797244Z","shell.execute_reply":"2023-06-22T16:18:30.755707Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.30.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.10.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.5.5)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=5174774de66c8ce9bb470e655de025b8deebcfb4b93ad542d7d6568784dfc1f7\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nmodel_1 = SentenceTransformer('all-MiniLM-L6-v2')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:18:36.106346Z","iopub.execute_input":"2023-06-22T16:18:36.106816Z","iopub.status.idle":"2023-06-22T16:18:53.602235Z","shell.execute_reply.started":"2023-06-22T16:18:36.106775Z","shell.execute_reply":"2023-06-22T16:18:53.600809Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)e9125/.gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2c2313f71fb468f8f31a72445f739fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50484131d4ef4b81af1bc74bb47e285c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e55de9125/README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dee738c744c49c090c474cb95d2d22a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4424c05ce0f9454996f4392efb0f8403"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fb9f80ccaef424285723d0af7cbb504"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)125/data_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"692dd13223f1454f8b94c50775ea1b06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa3b9f0e0d245c6a3bd8b1a2c66e39f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73e981408f3846ad8a971f444e2fd044"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45157d2a8d4f436fa4ee5612d96d70ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)e9125/tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3943a46a589f47be93f7ab28bd04b086"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03467dd97d7443d581d0a1c7c0696cab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)9125/train_script.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a4099ee19884bbdb3b0524a8449a4cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e55de9125/vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8d39c7eb26e40aeaea5e3afa501267e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5da0a8a1f6b84daaa6f9f5e08971fa6a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#import modules\nimport os\nimport pickle\nimport numpy as np\nfrom tqdm.notebook import tqdm\n\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.layers import Input, Dense, LSTM,Embedding,Dropout, add\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:19:00.812732Z","iopub.execute_input":"2023-06-22T16:19:00.813085Z","iopub.status.idle":"2023-06-22T16:19:00.824498Z","shell.execute_reply.started":"2023-06-22T16:19:00.813056Z","shell.execute_reply":"2023-06-22T16:19:00.823409Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"BASE_DIR= '/kaggle/input/flickr8k'\nWORKING_DIR='/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:19:16.763903Z","iopub.execute_input":"2023-06-22T16:19:16.764262Z","iopub.status.idle":"2023-06-22T16:19:16.768610Z","shell.execute_reply.started":"2023-06-22T16:19:16.764234Z","shell.execute_reply":"2023-06-22T16:19:16.767615Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## FEATURE EXTRACTION ","metadata":{}},{"cell_type":"code","source":"#LOAD VGG16\nmodel=VGG16()\nmodel=Model(inputs=model.inputs, outputs=model.layers[-2].output)\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:19:32.814079Z","iopub.execute_input":"2023-06-22T16:19:32.814496Z","iopub.status.idle":"2023-06-22T16:19:43.852928Z","shell.execute_reply.started":"2023-06-22T16:19:32.814465Z","shell.execute_reply":"2023-06-22T16:19:43.852137Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 3s 0us/step\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n fc1 (Dense)                 (None, 4096)              102764544 \n                                                                 \n fc2 (Dense)                 (None, 4096)              16781312  \n                                                                 \n=================================================================\nTotal params: 134,260,544\nTrainable params: 134,260,544\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"##extraction\n\nfeatures={}\ndirectory='/kaggle/input/flickr8k/Images'\n\nfor img_name in tqdm(os.listdir(directory)):\n    img_path= directory+'/'+ img_name\n    img=load_img(img_path,target_size=(224,224))\n    img=img_to_array(img)\n    img=img.reshape(1,img.shape[0],img.shape[1],img.shape[2])\n    img=preprocess_input(img)\n    feature=model.predict(img,verbose=0)\n    image_id=img_name.split('.')[0]\n    #store features\n    features[image_id]=feature\n    \ndirectory='/kaggle/input/stable-diffusion-image-to-prompts/images'\n\nfor img_name in tqdm(os.listdir(directory)):\n    img_path= directory+'/'+ img_name\n    img=load_img(img_path,target_size=(224,224))\n    img=img_to_array(img)\n    img=img.reshape(1,img.shape[0],img.shape[1],img.shape[2])\n    img=preprocess_input(img)\n    feature=model.predict(img,verbose=0)\n    image_id=img_name.split('.')[0]\n    #store features\n    features[image_id]=feature\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:19:54.466866Z","iopub.execute_input":"2023-06-22T16:19:54.467239Z","iopub.status.idle":"2023-06-22T16:31:13.496270Z","shell.execute_reply.started":"2023-06-22T16:19:54.467210Z","shell.execute_reply":"2023-06-22T16:31:13.495204Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8091 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846b504663384ad5a359fe4bbd7a62d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3e939fcced0436583c2a22d12280db3"}},"metadata":{}}]},{"cell_type":"code","source":"#storing features in pickle\npickle.dump(features,open(os.path.join(WORKING_DIR,'features.pkl'),'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:31:57.798967Z","iopub.execute_input":"2023-06-22T16:31:57.799348Z","iopub.status.idle":"2023-06-22T16:31:58.104622Z","shell.execute_reply.started":"2023-06-22T16:31:57.799316Z","shell.execute_reply":"2023-06-22T16:31:58.103604Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#load from pickle\nwith open(os.path.join(WORKING_DIR,'features.pkl') , \"rb\") as f:\n    features=pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:00.455622Z","iopub.execute_input":"2023-06-22T16:32:00.455985Z","iopub.status.idle":"2023-06-22T16:32:00.620072Z","shell.execute_reply.started":"2023-06-22T16:32:00.455956Z","shell.execute_reply":"2023-06-22T16:32:00.619050Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## LOADING CAPTION DATA\n","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/flickr8k/captions.txt', 'r') as f:\n    next(f)\n    captions_doc=f.read()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:03.935095Z","iopub.execute_input":"2023-06-22T16:32:03.935496Z","iopub.status.idle":"2023-06-22T16:32:03.982452Z","shell.execute_reply.started":"2023-06-22T16:32:03.935466Z","shell.execute_reply":"2023-06-22T16:32:03.981410Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import csv\n#mapping image to caption\nmapping={}\nfor line in tqdm(captions_doc.split('\\n')):\n    tokens=line.split(',')\n    if len(line)<2:\n        continue\n    image_id,caption= tokens[0],tokens[1:]\n    image_id=image_id.split('.')[0]\n    caption=\" \".join(caption)\n    \n    if image_id not in mapping:\n        mapping[image_id]=[]\n    \n    mapping[image_id].append(caption)\n    \n    \n\nfilename = \"/kaggle/input/stable-diffusion-image-to-prompts/prompts.csv\"  # Replace with the actual filename\n\nwith open(filename, 'r') as file:\n    reader = csv.reader(file)\n    for i, row in enumerate(reader):\n        if i != 0 and row:  # Skip the first row and empty rows\n            if row[0] not in mapping:\n                mapping[row[0]]=[]\n                \n            mapping[row[0]].append(row[1])\n            \n        \n             \n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:06.648432Z","iopub.execute_input":"2023-06-22T16:32:06.648827Z","iopub.status.idle":"2023-06-22T16:32:06.811576Z","shell.execute_reply.started":"2023-06-22T16:32:06.648797Z","shell.execute_reply":"2023-06-22T16:32:06.810418Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40456 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d5b29c488e04d5da2bb22e6c5f39a39"}},"metadata":{}}]},{"cell_type":"code","source":"def clean(mapping):\n    for key, captions in mapping.items():\n        for i in range(len(captions)):\n            caption=captions[i]\n            #preprocessing \n            caption=caption.lower()\n            caption=caption.replace('[A-Za-z]','')\n            caption=caption.replace('\\s+',' ')\n            caption='startseq '+\" \".join([word for word in caption.split() if len(word)>1])+ ' endseq'\n            captions[i]=caption","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:17.142920Z","iopub.execute_input":"2023-06-22T16:32:17.143310Z","iopub.status.idle":"2023-06-22T16:32:17.150203Z","shell.execute_reply.started":"2023-06-22T16:32:17.143280Z","shell.execute_reply":"2023-06-22T16:32:17.149173Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# preprocess \nclean(mapping)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:27.089137Z","iopub.execute_input":"2023-06-22T16:32:27.090923Z","iopub.status.idle":"2023-06-22T16:32:27.272894Z","shell.execute_reply.started":"2023-06-22T16:32:27.090879Z","shell.execute_reply":"2023-06-22T16:32:27.271749Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"all_captions=[]\nfor key in mapping:\n    for caption in mapping[key]:\n        all_captions.append(caption)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:30.713026Z","iopub.execute_input":"2023-06-22T16:32:30.713630Z","iopub.status.idle":"2023-06-22T16:32:30.733168Z","shell.execute_reply.started":"2023-06-22T16:32:30.713585Z","shell.execute_reply":"2023-06-22T16:32:30.731927Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#tokenization\ntokenizer=Tokenizer()\ntokenizer.fit_on_texts(all_captions)\nvocab_size=len(tokenizer.word_index)+1","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:33.165003Z","iopub.execute_input":"2023-06-22T16:32:33.165427Z","iopub.status.idle":"2023-06-22T16:32:33.968388Z","shell.execute_reply.started":"2023-06-22T16:32:33.165390Z","shell.execute_reply":"2023-06-22T16:32:33.966900Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"max_length=max(len(caption.split()) for caption in all_captions)\nmax_length","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:37.628887Z","iopub.execute_input":"2023-06-22T16:32:37.629520Z","iopub.status.idle":"2023-06-22T16:32:37.679408Z","shell.execute_reply.started":"2023-06-22T16:32:37.629486Z","shell.execute_reply":"2023-06-22T16:32:37.678383Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"35"},"metadata":{}}]},{"cell_type":"markdown","source":"# #train test split\n","metadata":{}},{"cell_type":"code","source":"image_ids=list(mapping.keys())\nsplit=int(len(image_ids)*0.9)\ntrain=image_ids[:split]\ntest=image_ids[split:]","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:43.847952Z","iopub.execute_input":"2023-06-22T16:32:43.848919Z","iopub.status.idle":"2023-06-22T16:32:43.855564Z","shell.execute_reply.started":"2023-06-22T16:32:43.848871Z","shell.execute_reply":"2023-06-22T16:32:43.854217Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#data generator\ndef data_generator(data_keys,mapping,features,tokenizer, max_length, vocab_size, batch_size):\n    X1,X2,y=list(),list(),list()\n    n=0\n    while 1:\n        for key in data_keys:\n            n+=1\n            captions=mapping[key]\n            for caption in captions:\n                #encode the seq\n                seq=tokenizer.texts_to_sequences([caption])[0]\n                #split into X,y pairs\n                for i in range(1,len(seq)):\n                    in_seq,out_seq=seq[:i],seq[i]\n                    #pad input seq\n                    in_seq=pad_sequences([in_seq],maxlen=max_length)[0]\n                    #encode seq\n                    out_seq=to_categorical([out_seq],num_classes=vocab_size)[0]\n                    \n                    X1.append(features[key][0])\n                    X2.append(in_seq)\n                    y.append(out_seq)\n            if n==batch_size:\n                X1,X2,y=np.array(X1),np.array(X2),np.array(y)\n                yield [X1,X2] , y\n                X1,X2,y=list(),list(),list()\n                n=0","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:05:37.271431Z","iopub.execute_input":"2023-06-22T12:05:37.271816Z","iopub.status.idle":"2023-06-22T12:05:37.282353Z","shell.execute_reply.started":"2023-06-22T12:05:37.271786Z","shell.execute_reply":"2023-06-22T12:05:37.281185Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## model creation","metadata":{}},{"cell_type":"code","source":"#encoder model\n#image feature layers\ninputs1=Input(shape=(4096,))\nf1=Dropout(0.4)(inputs1)\nf2=Dense(256,activation='relu')(f1)\n\n#seq feature layer\ninputs2=Input(shape=(max_length,))\ns1=Embedding(vocab_size,256,mask_zero=True)(inputs2)\ns2=Dropout(0.4)(s1)\ns3=LSTM(256)(s2)\n\n#decoder model\ndecoder1=add([f2,s3])\ndecoder2=Dense(256,activation='relu')(decoder1)\noutputs=Dense(vocab_size,activation='softmax')(decoder2)\n\nmodel=Model(inputs=[inputs1,inputs2], outputs=outputs)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n\n#plot_model(model,show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T05:28:39.101867Z","iopub.execute_input":"2023-06-22T05:28:39.102271Z","iopub.status.idle":"2023-06-22T05:28:40.227029Z","shell.execute_reply.started":"2023-06-22T05:28:39.102242Z","shell.execute_reply":"2023-06-22T05:28:40.226023Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#train the model\nepochs=18\nbatch_size=64\nsteps=len(train)//batch_size\n\nfor i in range(epochs):\n    generator=data_generator(train, mapping,features,tokenizer, max_length, vocab_size, batch_size)\n    model.fit(generator,epochs=1,steps_per_epoch=steps, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T05:28:46.150773Z","iopub.execute_input":"2023-06-22T05:28:46.151174Z","iopub.status.idle":"2023-06-22T05:48:11.902572Z","shell.execute_reply.started":"2023-06-22T05:28:46.151145Z","shell.execute_reply":"2023-06-22T05:48:11.901557Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"113/113 [==============================] - 77s 620ms/step - loss: 5.6266\n113/113 [==============================] - 60s 532ms/step - loss: 4.5062\n113/113 [==============================] - 60s 531ms/step - loss: 3.8623\n113/113 [==============================] - 60s 532ms/step - loss: 3.5500\n113/113 [==============================] - 60s 530ms/step - loss: 3.3409\n113/113 [==============================] - 60s 532ms/step - loss: 3.1752\n113/113 [==============================] - 60s 528ms/step - loss: 3.0465\n113/113 [==============================] - 61s 536ms/step - loss: 2.9421\n113/113 [==============================] - 60s 534ms/step - loss: 2.8562\n113/113 [==============================] - 61s 541ms/step - loss: 2.7742\n113/113 [==============================] - 61s 537ms/step - loss: 2.7032\n113/113 [==============================] - 62s 544ms/step - loss: 2.6483\n113/113 [==============================] - 61s 541ms/step - loss: 2.5930\n113/113 [==============================] - 62s 548ms/step - loss: 2.5424\n113/113 [==============================] - 61s 537ms/step - loss: 2.4959\n113/113 [==============================] - 62s 548ms/step - loss: 2.4524\n113/113 [==============================] - 60s 532ms/step - loss: 2.4128\n113/113 [==============================] - 63s 552ms/step - loss: 2.3791\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(WORKING_DIR+'/my_model_1.h5')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T05:48:20.786236Z","iopub.execute_input":"2023-06-22T05:48:20.786674Z","iopub.status.idle":"2023-06-22T05:48:20.945808Z","shell.execute_reply.started":"2023-06-22T05:48:20.786638Z","shell.execute_reply":"2023-06-22T05:48:20.944783Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## generate caption","metadata":{}},{"cell_type":"code","source":"#load model\nfrom tensorflow.keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:52.066697Z","iopub.execute_input":"2023-06-22T16:32:52.067060Z","iopub.status.idle":"2023-06-22T16:32:52.072470Z","shell.execute_reply.started":"2023-06-22T16:32:52.067031Z","shell.execute_reply":"2023-06-22T16:32:52.071103Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model=load_model('/kaggle/working/my_model_1.h5')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:32:57.503504Z","iopub.execute_input":"2023-06-22T16:32:57.504490Z","iopub.status.idle":"2023-06-22T16:32:59.508500Z","shell.execute_reply.started":"2023-06-22T16:32:57.504444Z","shell.execute_reply":"2023-06-22T16:32:59.507386Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def idx_to_word(integer,tokenizer):\n    for word,index in tokenizer.word_index.items():\n        if index==integer:\n            return word\n    return None\n            ","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:33:03.885008Z","iopub.execute_input":"2023-06-22T16:33:03.885413Z","iopub.status.idle":"2023-06-22T16:33:03.891735Z","shell.execute_reply.started":"2023-06-22T16:33:03.885371Z","shell.execute_reply":"2023-06-22T16:33:03.890490Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def caption_prediction(model,image,tokenizer,max_length):\n    in_text='startseq'\n    for i in range(max_length):\n        #encode input seq\n        sequence=tokenizer.texts_to_sequences([in_text])[0]\n        #pad the seq\n        sequence=pad_sequences([sequence],max_length)\n        #predict next word\n        yhat=model.predict([image,sequence],verbose=0)\n        yhat= np.argmax(yhat)\n        word=idx_to_word(yhat,tokenizer)\n        \n        if word is None:\n            break\n        in_text+=\" \"+ word\n        if word=='endseq':\n            break\n    return in_text","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:33:09.230772Z","iopub.execute_input":"2023-06-22T16:33:09.231187Z","iopub.status.idle":"2023-06-22T16:33:09.238546Z","shell.execute_reply.started":"2023-06-22T16:33:09.231154Z","shell.execute_reply":"2023-06-22T16:33:09.237430Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\n#validate with text data\nactual, predicted= list(),list()\n\nfor key in tqdm(test):\n    #get actual caption\n    captions= mapping[key]\n    #predicted caption\n    ypred=caption_prediction(model,features[key],tokenizer,max_length)\n    actual_captions=[caption.split() for caption in captions]\n    ypred=ypred.split()\n    actual.append(actual_captions)\n    predicted.append(ypred)\n    \n #bleu score\nprint(\"BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0,0,0,0)))\nprint(\"BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5,0.5,0,0)))","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:26:26.577567Z","iopub.execute_input":"2023-06-22T10:26:26.577924Z","iopub.status.idle":"2023-06-22T10:35:25.088597Z","shell.execute_reply.started":"2023-06-22T10:26:26.577891Z","shell.execute_reply":"2023-06-22T10:35:25.087456Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/810 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4af73dd0d324cbabb4dffff22a66bfc"}},"metadata":{}},{"name":"stdout","text":"BLEU-1: 0.539385\nBLEU-2: 0.317103\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## visualize the result","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\ndef generate_caption(image_name):\n    image_path=os.path.join(\"/kaggle/input/stable-diffusion-image-to-prompts/images\",image_name)\n    image_id=image_name.split('.')[0]\n    #image= Image.open(image_path)\n    #captions=mapping[image_id]\n    ypred=caption_prediction(model,features[image_id],tokenizer,max_length)\n    return ypred ","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:33:15.567152Z","iopub.execute_input":"2023-06-22T16:33:15.567540Z","iopub.status.idle":"2023-06-22T16:33:15.574530Z","shell.execute_reply.started":"2023-06-22T16:33:15.567509Z","shell.execute_reply":"2023-06-22T16:33:15.573243Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#load model\nfrom tensorflow.keras.models import load_model\nmodel_1=load_model('/kaggle/input/my-model/my_model_1.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsentences=[]\ndirectory='/kaggle/input/stable-diffusion-image-to-prompts/images'\n\nfor img_name in tqdm(os.listdir(directory)):\n    sentences.append(generate_caption(img_name))\n\n\nembeddings = model_1.encode(sentences)\nprint(embeddings)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:33:43.740890Z","iopub.execute_input":"2023-06-22T16:33:43.741394Z","iopub.status.idle":"2023-06-22T16:33:51.355084Z","shell.execute_reply.started":"2023-06-22T16:33:43.741341Z","shell.execute_reply":"2023-06-22T16:33:51.353930Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d49f80f591254b26976bad33804546e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24fe4b31c9254545b238de3fac82f5b7"}},"metadata":{}},{"name":"stdout","text":"[[-0.05959426  0.03174604 -0.06907127 ... -0.08785734 -0.04295547\n   0.03891272]\n [-0.06589831  0.06656386  0.04427902 ... -0.01740234  0.00573433\n   0.04439513]\n [ 0.01826437  0.0884907  -0.02657704 ...  0.03458299  0.00778888\n   0.06927446]\n ...\n [-0.00463759  0.08915918  0.02655171 ...  0.02230095  0.07641359\n  -0.03694128]\n [-0.02347468  0.01386189  0.08982924 ...  0.01323435  0.05274043\n   0.05073986]\n [-0.04374108  0.01773241  0.04756919 ... -0.02921897  0.00483093\n  -0.03782266]]\n","output_type":"stream"}]},{"cell_type":"code","source":"directory='/kaggle/input/stable-diffusion-image-to-prompts/images'\nlist_img=[]\n\nfor img_name in tqdm(os.listdir(directory)):\n    image_id=img_name.split('.')[0]\n    list_img.append(image_id)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T16:58:41.687003Z","iopub.execute_input":"2023-06-22T16:58:41.687435Z","iopub.status.idle":"2023-06-22T16:58:41.717140Z","shell.execute_reply.started":"2023-06-22T16:58:41.687399Z","shell.execute_reply":"2023-06-22T16:58:41.716072Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dc01d7f863b4bbd80206a0079ffa365"}},"metadata":{}}]},{"cell_type":"code","source":"list_img.sort()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T17:09:01.153407Z","iopub.execute_input":"2023-06-22T17:09:01.153849Z","iopub.status.idle":"2023-06-22T17:09:01.161972Z","shell.execute_reply.started":"2023-06-22T17:09:01.153815Z","shell.execute_reply":"2023-06-22T17:09:01.160753Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"['20057f34d',\n '227ef0887',\n '92e911621',\n 'a4e1c55a9',\n 'c98f79f71',\n 'd8edf2e40',\n 'f27825b2c']"},"metadata":{}}]},{"cell_type":"code","source":"\ndef save_embeddings_to_csv(embeddings_list, filename):\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['img_id', '#values'])\n        for image_id, embeddings in enumerate(embeddings_list, start=0):\n            for index, embedding in enumerate(embeddings):\n                writer.writerow([f'{list_img[image_id]}_{index+1}', embedding])\n\nsave_embeddings_to_csv(embeddings, 'submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T17:14:10.362501Z","iopub.execute_input":"2023-06-22T17:14:10.363722Z","iopub.status.idle":"2023-06-22T17:14:10.381777Z","shell.execute_reply.started":"2023-06-22T17:14:10.363670Z","shell.execute_reply":"2023-06-22T17:14:10.380610Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}